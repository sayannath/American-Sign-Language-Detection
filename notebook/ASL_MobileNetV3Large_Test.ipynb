{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASL_MobileNetV3Large-Test.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmVItFEWipNy"
      },
      "source": [
        "# American Sign Language - MobileNetV3 Large Inference\n",
        "\n",
        "Author: [Sayan Nath](https://github.com/sayannath)\n",
        "\n",
        "Dataset Link: [Kaggle ASL](https://www.kaggle.com/grassknoted/asl-alphabet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTOwAk_-iUhD"
      },
      "source": [
        "## Initial Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nJpWPDLh7KN",
        "outputId": "7f8755d0-d328-41b3-ec78-127125cb3ddf"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Mar 29 22:46:55 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRM2gJ7XNKsz"
      },
      "source": [
        "## Getting the Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ7lSe5NKzpg"
      },
      "source": [
        "cp -r /content/drive/MyDrive/ASL_MobileNetV3/asl_model.tar.gz /content/"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgLOkur_K3ci"
      },
      "source": [
        "!tar xf asl_model.tar.gz"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47xyLIvmqMtF"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V2V_FYsp5X1",
        "outputId": "6f3277a4-8f39-48fe-85d9-efb532946958"
      },
      "source": [
        "!pip uninstall -y tensorflow\n",
        "!pip install -q tf-nightly"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.4.1:\n",
            "  Successfully uninstalled tensorflow-2.4.1\n",
            "\u001b[K     |████████████████████████████████| 454.3MB 42kB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0MB 47.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 471kB 49.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.0MB 47.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0MB 49.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 44.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.9MB 52.3MB/s \n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amOMfwAEofLb"
      },
      "source": [
        "## Convert Saved Model to TF-Lite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuFvWpr_osAH",
        "outputId": "f9ee15b1-4e21-4aa7-a6d4-f0569a04c360"
      },
      "source": [
        "import tensorflow as tf\n",
        "from imutils import paths\n",
        "print(tf.__version__)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enabling eager execution\n",
            "INFO:tensorflow:Enabling v2 tensorshape\n",
            "INFO:tensorflow:Enabling resource variables\n",
            "INFO:tensorflow:Enabling tensor equality\n",
            "INFO:tensorflow:Enabling control flow v2\n",
            "2.6.0-dev20210329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcbfqeqXrbjl"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q47sYKVboTAh",
        "outputId": "8fc206b5-a2ea-4ef0-ca30-4ab8a593316d"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"asl_model\")\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS \n",
        "]\n",
        "tflite_model = converter.convert()\n",
        "open(\"asl.tflite\", 'wb').write(tflite_model)\n",
        "print('Model size is %f MBs.' % (len(tflite_model) / 1024 / 1024.0))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size is 9.559601 MBs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMFQrcLLozK0",
        "outputId": "9a60b33d-ec96-421e-b6ed-f4512bca6e2b"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_path = 'asl.tflite')\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Shape: [  1 224 224   3]\n",
            "Input Type: <class 'numpy.float32'>\n",
            "Output Shape: [ 1 29]\n",
            "Output Type: <class 'numpy.float32'>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}